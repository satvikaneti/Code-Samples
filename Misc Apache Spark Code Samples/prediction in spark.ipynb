{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95-869: Big Data and Large-Scale Computing Homework 3\n",
    "\n",
    "\n",
    "## **Click-Through Rate Prediction Assignment**\n",
    "#### This assignment covers the steps for creating a click-through rate (CTR) prediction pipeline.  You will work with the [Criteo Labs](http://labs.criteo.com/) dataset that was used for a recent [Kaggle competition](https://www.kaggle.com/c/criteo-display-ad-challenge).\n",
    "\n",
    "### About the Display Advertising Dataset\n",
    "\n",
    "\n",
    "This dataset contains feature values and click feedback for millions of display ads. Its purpose is to benchmark algorithms for clickthrough rate (CTR) prediction.\n",
    "\n",
    "The dataset consists of a portion of Criteo's traffic over a period of 7 days. Each row corresponds to a display ad served by Criteo and the first column is indicates whether this ad has been clicked or not. The positive (clicked) and negatives (non-clicked) examples have both been subsampled (but at different rates) in order to reduce the dataset size.\n",
    "\n",
    "There are 13 features taking integer values (mostly count features) and 26 categorical features. The values of the categorical features have been hashed onto 32 bits for anonymization purposes. The semantic of these features is undisclosed. Some features may have missing values.\n",
    "\n",
    "The rows are chronologically ordered. When a value is missing, the field is just empty.\n",
    "\n",
    "Dataset was assembled by Olivier Chapelle (o.chapelle@criteo.com)\n",
    "\n",
    "### ** This assignment will cover: **\n",
    "*  *Part 1 (10 Points):* Featurize categorical data using one-hot-encoding (OHE)\n",
    "*  *Part 2 (10 Points):* Construct an OHE dictionary\n",
    "*  *Part 3 (10 Points):* Parse CTR data and generate OHE features\n",
    "  * *Visualization 1 (10 Points):* Feature frequency\n",
    "*  *Part 4 (15 Points):* CTR prediction and logloss evaluation\n",
    "  * *Visualization 2 (15 Points):* ROC curve\n",
    "*  *Part 5 (15 Points):* Reduce feature dimension via feature hashing\n",
    "  * *Visualization 3 (15 Points):* Hyperparameter heat map\n",
    " \n",
    "#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions:\n",
    "\n",
    "You will submit both a PDF and an IPython file on Canvas. No printout submission is expected.\n",
    "\n",
    "Rename the notebook from \"hw3_ctr_student.ipynb\" to \"groupid_hw3_ctr_student.ipynb\" where \"groupid\" is your group id or your Andrew ID if you are working on your own. Complete the assignment, execute all cells in the completed notebook, and make sure all results show up. Export the contents of the notebook by choosing \"File > Download as > HTML\" and saving the resulting file as \"groupid_hw3_ctr_student.html\" Convert the exported HTML file to PDF by using a feature such as the \"Save as PDF\" feature on Mac. Submit the PDF solution to **gradescope**. Submit the IPython and exported PDF solution files on **Canvas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Featurize categorical data using one-hot-encoding **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) One-hot-encoding **\n",
    "#### We would like to develop code to convert categorical features to numerical ones, and to build intuition, we will work with a sample unlabeled dataset with three data points, with each data point representing an animal. The first feature indicates the type of animal (bear, cat, mouse); the second feature describes the animal's color (black, tabby); and the third (optional) feature describes what the animal eats (mouse, salmon).\n",
    "#### In a one-hot-encoding (OHE) scheme, we want to represent each tuple of `(featureID, category)` via its own binary feature.  We can do this in Python by creating a dictionary that maps each tuple to a distinct integer, where the integer corresponds to a binary feature. To start, manually enter the entries in the OHE dictionary associated with the sample dataset by mapping the tuples to consecutive integers starting from zero,  ordering the tuples first by featureID and next by category.\n",
    "#### Later in this lab, we'll use OHE dictionaries to transform data points into compact lists of features that can be used in machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://r090.pvt.bridges.psc.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"/opt/packages/spark/latest/python/lib/py4j-0.10.7-src.zip\")\n",
    "sys.path.append(\"/opt/packages/spark/latest/python/\")\n",
    "sys.path.append(\"/opt/packages/spark/latest/python/pyspark\")\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for manual OHE\n",
    "# Note: the first data point does not include any value for the optional third feature\n",
    "sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
    "sampleDataRDD = sc.parallelize([sampleOne, sampleTwo, sampleThree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually construct OHE for all categorical features\n",
    "sampleOHEDictManual = {}\n",
    "sampleOHEDictManual[(0,'bear')] = 0\n",
    "sampleOHEDictManual[(0,'cat')] = 1\n",
    "sampleOHEDictManual[(0,'mouse')] = 2\n",
    "sampleOHEDictManual[(1,'black')] = 3\n",
    "sampleOHEDictManual[(1,'tabby')] = 4\n",
    "sampleOHEDictManual[(2,'mouse')] = 5\n",
    "sampleOHEDictManual[(2,'salmon')] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Sparse vectors **\n",
    "#### Data points can typically be represented with a small number of non-zero OHE features relative to the total number of features that occur in the dataset.  By leveraging this sparsity and using sparse vector representations of OHE data, we can reduce storage and computational burdens.  Below are a few sample vectors represented as dense numpy arrays.  Use [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) to represent them in a sparse fashion, and verify that both the sparse and dense representations yield the same results when computing [dot products](http://en.wikipedia.org/wiki/Dot_product) (we will later use MLlib to train classifiers via gradient descent, and MLlib will need to compute dot products between SparseVectors and dense parameter vectors).\n",
    "#### Use `SparseVector(size, *args)` to create a new sparse vector where size is the length of the vector and args is either a dictionary, a list of (index, value) pairs, or two separate arrays of indices and values (sorted by index).  You'll need to create a sparse vector representation of each dense vector `aDense` and `bDense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.300000000000001\n",
      "7.300000000000001\n",
      "-0.5\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "aDense = np.array([0., 3., 0., 4.])\n",
    "aSparse = SparseVector(4, [1,3], [3,4])\n",
    "\n",
    "bDense = np.array([0., 0., 0., 1.])\n",
    "bSparse = SparseVector(4, [3], [1])\n",
    "\n",
    "w = np.array([0.4, 3.1, -1.4, -.5])\n",
    "print (aDense.dot(w))\n",
    "print (aSparse.dot(w))\n",
    "print (bDense.dot(w))\n",
    "print (bSparse.dot(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) OHE features as sparse vectors **\n",
    "#### Now let's see how we can represent the OHE features for points in our sample dataset.  Using the mapping defined by the OHE dictionary from Part (1a), manually define OHE features for the three sample data points using SparseVector format.  Any feature that occurs in a point should have the value 1.0.  For example, the `DenseVector` for a point with features 2 and 4 would be `[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of the sample features\n",
    "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOneOHEFeatManual = SparseVector(7, [2,3], [1.,1.])\n",
    "sampleTwoOHEFeatManual = SparseVector(7, [1,4,5], [1.,1.,1.])\n",
    "sampleThreeOHEFeatManual = SparseVector(7, [0,3,6], [1.,1.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1d) Define a OHE function **\n",
    "#### Next we will use the OHE dictionary from Part (1a) to programatically generate OHE features from the original categorical data.  First write a function called `oneHotEncoding` that creates OHE feature vectors in `SparseVector` format.  Then use this function to create OHE features for the first sample data point and verify that the result matches the result from Part (1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,[2,3],[1.0,1.0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def oneHotEncoding(rawFeats, OHEDict):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "        \n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0. Here numOHEFeats is the total number of unique OHE features\n",
    "            (combinations of featureID and value).\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for feat in rawFeats:\n",
    "        indices.append(OHEDict[feat])\n",
    "    return SparseVector(len(OHEDict), sorted(indices), [1. for i in range(len(indices))])\n",
    "\n",
    "# Run oneHotEnoding on sampleOne\n",
    "sampleOneOHEFeat = oneHotEncoding(sampleOne, sampleOHEDictManual)\n",
    "\n",
    "print (sampleOneOHEFeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1e) Apply OHE to a dataset **\n",
    "#### Finally, use the function from Part (1d) to create OHE features for all 3 data points in the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseVector(7, {2: 1.0, 3: 1.0}), SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}), SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0})]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEData = sampleDataRDD.map(lambda x: oneHotEncoding(x, sampleOHEDictManual))\n",
    "print (sampleOHEData.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 2: Construct an OHE dictionary **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Pair RDD of `(featureID, category)` **\n",
    "#### To start, create an RDD of distinct `(featureID, category)` tuples. In our sample dataset, the 7 items in the resulting RDD are `(0, 'bear')`, `(0, 'cat')`, `(0, 'mouse')`, `(1, 'black')`, `(1, 'tabby')`, `(2, 'mouse')`, `(2, 'salmon')`. Notably `'black'` appears twice in the dataset but only contributes one item to the RDD: `(1, 'black')`, while `'mouse'` also appears twice and contributes two items: `(0, 'mouse')` and `(2, 'mouse')`.  Use [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) and [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'mouse'), (0, 'bear'), (1, 'black'), (1, 'tabby'), (0, 'mouse'), (2, 'salmon'), (0, 'cat')]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleDistinctFeats = (sampleDataRDD\n",
    "                       .flatMap(lambda x: x).distinct())\n",
    "print(sampleDistinctFeats.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2b) OHE Dictionary from distinct features **\n",
    "#### Next, create an `RDD` of key-value tuples, where each `(featureID, category)` tuple in `sampleDistinctFeats` is a key and the values are distinct integers ranging from 0 to (number of keys - 1).  Then convert this `RDD` into a dictionary, which can be done using the `collectAsMap` action.  Note that there is no unique mapping from keys to values, as all we require is that each `(featureID, category)` key be mapped to a unique integer between 0 and the number of keys.  In this exercise, any valid mapping is acceptable.  Use [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) followed by [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap).\n",
    "#### In our sample dataset, one valid list of key-value tuples is: `[((0, 'bear'), 0), ((2, 'salmon'), 1), ((1, 'tabby'), 2), ((2, 'mouse'), 3), ((0, 'mouse'), 4), ((0, 'cat'), 5), ((1, 'black'), 6)]`. The dictionary defined in Part (1a) illustrates another valid mapping between keys and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 0, (0, 'bear'): 1, (1, 'black'): 2, (1, 'tabby'): 3, (0, 'mouse'): 4, (2, 'salmon'): 5, (0, 'cat'): 6}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEDict = (sampleDistinctFeats\n",
    "                           .zipWithIndex().collectAsMap())\n",
    "print (sampleOHEDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Automated creation of an OHE dictionary **\n",
    "#### Now use the code from Parts (2a) and (2b) to write a function that takes an input dataset and outputs an OHE dictionary.  Then use this function to create an OHE dictionary for the sample dataset, and verify that it matches the dictionary from Part (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 0, (0, 'bear'): 1, (1, 'black'): 2, (1, 'tabby'): 3, (0, 'mouse'): 4, (2, 'salmon'): 5, (0, 'cat'): 6}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def createOneHotDict(inputData):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n",
    "            made up of a list of (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    return inputData.flatMap(lambda x: x).distinct().zipWithIndex().collectAsMap()\n",
    "\n",
    "sampleOHEDictAuto = createOneHotDict(sampleDataRDD)\n",
    "print (sampleOHEDictAuto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Parse CTR data and generate OHE features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we can proceed, let's load the data from Criteo. If you want to see what it looks like, you can check [here](https://canvas.cmu.edu/courses/18986/files/5299970?module_item_id=4592172)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPartitions = 10\n",
    "\n",
    "rawData = sc.textFile('file:///pylon5/ci5619p/benh/dac_bigdata.txt', numPartitions)\n",
    "rawData = rawData.map(lambda x: x.strip().replace('\\t', ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3a) Loading and splitting the data **\n",
    "#### We are now ready to start working with the actual CTR data, and our first task involves splitting it into training, validation, and test sets.  Use the [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) with the specified weights and seed to create RDDs storing each of these datasets, and then [cache](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cache) each of these RDDs, as we will be accessing them multiple times in the remainder of this lab. Finally, compute the size of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80066 10020 9914 100000\n",
      "['0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights,seed)\n",
    "# Cache the data\n",
    "rawTrainData.cache()\n",
    "rawValidationData.cache()\n",
    "rawTestData.cache()\n",
    "\n",
    "nTrain = rawTrainData.count()\n",
    "nVal = rawValidationData.count()\n",
    "nTest = rawTestData.count()\n",
    "print (nTrain, nVal, nTest, nTrain + nVal + nTest)\n",
    "print (rawData.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3b) Extract features **\n",
    "#### We will now parse the raw training data to create an RDD that we can subsequently use to create an OHE dictionary. Note from the `take()` command in Part (3a) that each raw data point is a string containing several fields separated by some delimiter.  For now, we will ignore the first field (which is the 0-1 label), and parse the remaining fields (or raw features).  To do this, complete the implemention of the `parsePoint` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    splitpoint = point.split(\",\")\n",
    "    features = splitpoint[1:]\n",
    "    newfeatures = []\n",
    "    for i in range(len(features)):\n",
    "        newfeatures.append((i,features[i]))\n",
    "    return newfeatures\n",
    "    \n",
    "\n",
    "parsedTrainFeat = rawTrainData.map(parsePoint)\n",
    "\n",
    "numCategories = (parsedTrainFeat\n",
    "                 .flatMap(lambda x: x)\n",
    "                 .distinct()\n",
    "                 .map(lambda x: (x[0], 1))\n",
    "                 .reduceByKey(lambda x, y: x + y)\n",
    "                 .sortByKey()\n",
    "                 .collect())\n",
    "\n",
    "print (numCategories[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3c) Create an OHE dictionary from the dataset **\n",
    "#### Note that parsePoint returns a data point as a list of `(featureID, category)` tuples, which is the same format as the sample dataset studied in Parts 1 and 2 of this lab.  Using this observation, create an OHE dictionary using the function implemented in Part (2c). Note that we will assume for simplicity that all features in our CTR dataset are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234093\n",
      "93886\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "ctrOHEDict = createOneHotDict(parsedTrainFeat)\n",
    "numCtrOHEFeats = len(ctrOHEDict.keys())\n",
    "print (numCtrOHEFeats)\n",
    "print (ctrOHEDict[(0, '')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3d) Apply OHE to the dataset **\n",
    "#### Now let's use this OHE dictionary by starting with the raw training data and creating an RDD of [LabeledPoint](http://spark.apache.org/docs/1.3.1/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) objects using OHE features.  To do this, complete the implementation of the `parseOHEPoint` function. Hint: `parseOHEPoint` is an extension of the `parsePoint` function from Part (3b) and it uses the `oneHotEncoding` function from Part (1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (234093,[0,1,2,3,4,5,23404,23405,23406,23407,23408,46791,46792,46793,46794,70286,70287,93874,93875,93876,93877,117127,117128,117129,117130,117131,163996,163997,163998,187356,187357,187358,187359,210865,210866,210867,210868,210869,210870],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def parseOHEPoint(point, OHEDict):\n",
    "    \"\"\"Obtain the label and feature vector for this raw observation.\n",
    "\n",
    "    Note:\n",
    "        You must use the function `oneHotEncoding` in this implementation or later portions\n",
    "        of this lab may not function as expected.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "        OHEDict (dict of (int, str) to int): Mapping of (featureID, value) to unique integer.\n",
    "        \n",
    "    Returns:\n",
    "        LabeledPoint: Contains the label for the observation and the one-hot-encoding of the\n",
    "            raw features based on the provided OHE dictionary.\n",
    "    \"\"\"\n",
    "    splitpoint = point.split(\",\")\n",
    "    label = splitpoint[0]\n",
    "    features = splitpoint[1:]\n",
    "    newfeatures = []\n",
    "    for i in range(len(features)):\n",
    "        newfeatures.append((i,features[i]))\n",
    "    return LabeledPoint(label,oneHotEncoding(newfeatures, OHEDict))\n",
    "    \n",
    "\n",
    "OHETrainData = rawTrainData.map(lambda point: parseOHEPoint(point, ctrOHEDict))\n",
    "OHETrainData.cache()\n",
    "print (OHETrainData.take(1))\n",
    "\n",
    "# Check that oneHotEncoding function was used in parseOHEPoint\n",
    "backupOneHot = oneHotEncoding\n",
    "oneHotEncoding = None\n",
    "withOneHot = False\n",
    "try: parseOHEPoint(rawTrainData.take(1)[0], ctrOHEDict)\n",
    "except TypeError: withOneHot = True\n",
    "oneHotEncoding = backupOneHot\n",
    "print(withOneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualization 1: Feature frequency **\n",
    "#### We will now visualize the number of times each of the 234,093 OHE features appears in the training data. We first compute the number of times each feature appears, then bucket the features by these counts.  The buckets are sized by powers of 2, so the first bucket corresponds to features that appear exactly once ( $ \\scriptsize 2^0 $ ), the second to features that appear twice ( $ \\scriptsize 2^1 $ ), the third to features that occur between three and four ( $ \\scriptsize 2^2 $ ) times, the fifth bucket is five to eight ( $ \\scriptsize 2^3 $ ) times and so on. The scatter plot below shows the logarithm of the bucket thresholds versus the logarithm of the number of features that have counts that fall in the buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 163763), (32, 4780), (512, 415), (2, 23714), (1024, 257), (64, 2618), (4, 16818), (16, 7742), (256, 742), (128, 1490), (8, 11465)]\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "def bucketFeatByCount(featCount):\n",
    "    \"\"\"Bucket the counts by powers of two.\"\"\"\n",
    "    for i in range(11):\n",
    "        size = 2 ** i\n",
    "        if featCount <= size:\n",
    "            return size\n",
    "    return -1\n",
    "\n",
    "featCounts = (OHETrainData\n",
    "              .flatMap(lambda lp: lp.features.indices)\n",
    "              .map(lambda x: (x, 1))\n",
    "              .reduceByKey(add))\n",
    "featCountsBuckets = (featCounts\n",
    "                     .map(lambda x: (bucketFeatByCount(x[1]), 1))\n",
    "                     .filter(lambda t: t[0] != -1)\n",
    "                     .reduceByKey(add)\n",
    "                     .collect())\n",
    "print (featCountsBuckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1050x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = zip(*featCountsBuckets)\n",
    "x, y = np.log(x), np.log(y)\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0, 10, 1), np.arange(4, 14, 2))\n",
    "ax.set_xlabel(r'$\\log_e(bucketSize)$'), ax.set_ylabel(r'$\\log_e(countInBucket)$')\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3e) Handling unseen features **\n",
    "#### We naturally would like to repeat the process from Part (3d), e.g., to compute OHE features for the validation and test datasets.  However, we must be careful, as some categorical values will likely appear in new data that did not exist in the training data. To deal with this situation, update the `oneHotEncoding()` function from Part (1d) to ignore previously unseen categories, and then compute OHE features for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (234093,[0,4,17,130,284,23410,23415,23777,24357,24358,46810,70292,71324,80958,93878,93886,93902,93906,94893,117130,117138,117140,118102,118103,140688,140710,163999,164002,164011,164221,164637,165006,187357,187366,188386,188387,210869],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def oneHotEncoding(rawFeats, OHEDict):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        If a (featureID, value) tuple doesn't have a corresponding key in OHEDict it should be\n",
    "        ignored.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0. Here numOHEFeats is the total number of unique OHE features\n",
    "            (combinations of featureID and value).\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for feat in rawFeats:\n",
    "        if feat in OHEDict:\n",
    "            indices.append(OHEDict[feat])\n",
    "    return SparseVector(len(OHEDict), sorted(indices), [1. for i in range(len(indices))])\n",
    "\n",
    "OHEValidationData = rawValidationData.map(lambda point: parseOHEPoint(point, ctrOHEDict))\n",
    "OHEValidationData.cache()\n",
    "print (OHEValidationData.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 4: CTR prediction and logloss evaluation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4a) Logistic regression **\n",
    "#### We are now ready to train our first CTR classifier.  A natural classifier to use in this setting is logistic regression, since it models the probability of a click-through event rather than returning a binary response, and when working with rare events, probabilistic predictions are useful.  First use [LogisticRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD) to train a model using `OHETrainData` with the given hyperparameter configuration.  `LogisticRegressionWithSGD` returns a [LogisticRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LogisticRegressionModel).  Next, use the `LogisticRegressionModel.weights` and `LogisticRegressionModel.intercept` attributes to print out the model's parameters.  Note that these are the names of the object's attributes and should be called using a syntax like `model.weights` for a given `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "# fixed hyperparameters\n",
    "numIters = 50\n",
    "stepSize = 10.\n",
    "regParam = 1e-6\n",
    "regType = 'l2'\n",
    "includeIntercept = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45416127798210476, -0.37916600722432536, -0.3720623341636577, -0.3694868757138, -0.3245669073058559] 0.5623499479626822\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "model0 = LogisticRegressionWithSGD.train(data = OHETrainData, iterations = numIters, step = stepSize, regParam = regParam, regType = regType, intercept = includeIntercept)\n",
    "sortedWeights = sorted(model0.weights)\n",
    "print (sortedWeights[:5], model0.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4b) Log loss **\n",
    "#### Throughout this lab, we will use log loss to evaluate the quality of models.  Log loss is defined as: $$  \\begin{align} \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\end{align} $$ where $ \\scriptsize p$ is a probability between 0 and 1 and $ \\scriptsize y$ is a label of either 0 or 1. Log loss is a standard evaluation criterion when predicting rare-events such as click-through rate prediction (it is also the criterion used in the [Criteo Kaggle competition](https://www.kaggle.com/c/criteo-display-ad-challenge)).  Write a function to compute log loss, and evaluate it on some sample inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n",
      "0.6931471805599453\n",
      "0.01005033585350145\n",
      "4.605170185988091\n",
      "4.605170185988091\n",
      "0.01005033585350145\n",
      "25.328436022934504\n",
      "1.000000082745371e-11\n",
      "1.3862943611198906\n",
      "0.2876820724517809\n",
      "1.000000082745371e-11\n",
      "25.328435940194137\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from math import log\n",
    "\n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if p == 0:\n",
    "        p+= epsilon\n",
    "    if p == 1:\n",
    "        p -= epsilon\n",
    "        \n",
    "    if y == 0:\n",
    "        return -log(1-p)\n",
    "    elif y == 1:\n",
    "        return -log(p)\n",
    "\n",
    "print (computeLogLoss(.5, 1))\n",
    "print (computeLogLoss(.5, 0))\n",
    "print (computeLogLoss(.99, 1))\n",
    "print (computeLogLoss(.99, 0))\n",
    "print (computeLogLoss(.01, 1))\n",
    "print (computeLogLoss(.01, 0))\n",
    "print (computeLogLoss(0, 1))\n",
    "print (computeLogLoss(0, 0))\n",
    "print (computeLogLoss(.25, 1))\n",
    "print (computeLogLoss(.25, 0))\n",
    "print (computeLogLoss(1, 1))\n",
    "print (computeLogLoss(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4c)  Baseline log loss **\n",
    "#### Next we will use the function we wrote in Part (4b) to compute the baseline log loss on the training data. A very simple yet natural baseline model is one where we always make the same prediction independent of the given datapoint, setting the predicted value equal to the fraction of training points that correspond to click-through events (i.e., where the label is one). Compute this value (which is simply the mean of the training labels), and then use it to compute the training log loss for the baseline model.  The log loss for multiple observations is the mean of the individual log loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2272375290385432\n",
      "Baseline Train Logloss = 0.536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Note that our dataset has a very high click-through rate by design\n",
    "# In practice click-through rate can be one to two orders of magnitude lower\n",
    "classOneFracTrain = OHETrainData.map(lambda x: x.label).mean()\n",
    "print (classOneFracTrain)\n",
    "\n",
    "logLossTrBase = OHETrainData.map(lambda x: (classOneFracTrain, x.label)).map(lambda x: computeLogLoss(x[0],x[1])).mean()\n",
    "print ('Baseline Train Logloss = {0:.3f}\\n'.format(logLossTrBase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4d) Predicted probability **\n",
    "#### In order to compute the log loss for the model we trained in Part (4a), we need to write code to generate predictions from this model. Write a function that computes the raw linear prediction from this logistic regression model and then passes it through a [sigmoid function](http://en.wikipedia.org/wiki/Sigmoid_function) $ \\scriptsize \\sigma(t) = (1+ e^{-t})^{-1} $ to return the model's probabilistic prediction. Then compute probabilistic predictions on the training data.\n",
    "#### Note that when incorporating an intercept into our predictions, we simply add the intercept to the value of the prediction obtained from the weights and features.  Alternatively, if the intercept was included as the first weight, we would need to add a corresponding feature to our data where the feature has the value one.  This is not the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29127805566633835, 0.10213812172552388, 0.29253604392199584, 0.16861928189218603, 0.5719744057299744]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w) + intercept\n",
    "\n",
    "    # Bound the raw prediction value\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return (1+exp(-rawPrediction))**-1\n",
    "\n",
    "trainingPredictions = OHETrainData.map(lambda x: getP(x.features, model0.weights, model0.intercept))\n",
    "\n",
    "print (trainingPredictions.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4e) Evaluate the model **\n",
    "#### We are now ready to evaluate the quality of the model we trained in Part (4a). To do this, first write a general function that takes as input a model and data, and outputs the log loss.  Then run this function on the OHE training data, and compare the result with the baseline log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Train Logloss:\n",
      "\tBaseline = 0.536\n",
      "\tLogReg = 0.457\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    return data.map(lambda x: (getP(x.features, model.weights, model.intercept),x.label)).map(lambda x: computeLogLoss(x[0],x[1])).mean()\n",
    "\n",
    "logLossTrLR0 = evaluateResults(model0, OHETrainData)\n",
    "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossTrBase, logLossTrLR0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4f) Validation log loss **\n",
    "#### Next, following the same logic as in Parts (4c) and 4(e), compute the validation log loss for both the baseline and logistic regression models. Notably, the baseline model for the validation data should still be based on the label fraction from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Validation Logloss:\n",
      "\tBaseline = 0.530\n",
      "\tLogReg = 0.456\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "logLossValBase = OHEValidationData.map(lambda x: (classOneFracTrain, x.label)).map(lambda x: computeLogLoss(x[0],x[1])).mean()\n",
    "\n",
    "logLossValLR0 = evaluateResults(model0,OHEValidationData)\n",
    "print ('OHE Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossValBase, logLossValLR0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualization 2: ROC curve **\n",
    "#### We will now visualize how well the model predicts our target.  To do this we generate a plot of the ROC curve.  The ROC curve shows us the trade-off between the false positive rate and true positive rate, as we liberalize the threshold required to predict a positive outcome.  A random model is represented by the dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 756x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelsAndScores = OHEValidationData.map(lambda lp:\n",
    "                                            (lp.label, getP(lp.features, model0.weights, model0.intercept)))\n",
    "labelsAndWeights = labelsAndScores.collect()\n",
    "labelsAndWeights.sort(key=lambda t: t[1], reverse=True)\n",
    "labelsByWeight = np.array([k for (k, v) in labelsAndWeights])\n",
    "\n",
    "length = labelsByWeight.size\n",
    "truePositives = labelsByWeight.cumsum()\n",
    "numPositive = truePositives[-1]\n",
    "falsePositives = np.arange(1.0, length + 1, 1.) - truePositives\n",
    "\n",
    "truePositiveRate = truePositives / numPositive\n",
    "falsePositiveRate = falsePositives / (length - numPositive)\n",
    "\n",
    "# Generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0., 1.1, 0.1), np.arange(0., 1.1, 0.1))\n",
    "ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.plot(falsePositiveRate, truePositiveRate, color='#8cbfd0', linestyle='-', linewidth=3.)\n",
    "plt.plot((0., 1.), (0., 1.), linestyle='--', color='#d6ebf2', linewidth=2.)  # Baseline model\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5: Reduce feature dimension via feature hashing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5a) Hash function **\n",
    "#### As we just saw, using a one-hot-encoding featurization can yield a model with good statistical accuracy.  However, the number of distinct categories across all features is quite large -- recall that we observed 234K categories in the training data in Part (3c).  Moreover, the full Kaggle training dataset includes more than 33M distinct categories, and the Kaggle dataset itself is just a small subset of Criteo's labeled data.  Hence, featurizing via a one-hot-encoding representation would lead to a very large feature vector. To reduce the dimensionality of the feature space, we will use feature hashing.\n",
    "#### Below is the hash function that we will use for this part of the lab.  We will first use this hash function with the three sample data points from Part (1a) to gain some intuition.  Specifically, run code to hash the three sample points using two different values for `numBuckets` and observe the resulting hashed feature dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString.encode('utf-8')).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print (mapping)\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)\n",
    "\n",
    "# Reminder of the sample values:\n",
    "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mouse0': 1, 'black1': 4}\n",
      "{'cat0': 0, 'tabby1': 1, 'mouse2': 2}\n",
      "{'bear0': 2, 'black1': 4, 'salmon2': 0}\n",
      "{'mouse0': 31, 'black1': 14}\n",
      "{'cat0': 40, 'tabby1': 16, 'mouse2': 62}\n",
      "{'bear0': 72, 'black1': 14, 'salmon2': 5}\n",
      "\t\t 5 Buckets \t\t\t 100 Buckets\n",
      "SampleOne:\t {1: 1.0, 4: 1.0}\t\t {31: 1.0, 14: 1.0}\n",
      "SampleTwo:\t {0: 1.0, 1: 1.0, 2: 1.0}\t\t {40: 1.0, 16: 1.0, 62: 1.0}\n",
      "SampleThree:\t {2: 1.0, 4: 1.0, 0: 1.0}\t {72: 1.0, 14: 1.0, 5: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Use five buckets\n",
    "sampOneFiveBuckets = hashFunction(5, sampleOne, True)\n",
    "sampTwoFiveBuckets = hashFunction(5, sampleTwo, True)\n",
    "sampThreeFiveBuckets = hashFunction(5, sampleThree, True)\n",
    "\n",
    "# Use one hundred buckets\n",
    "sampOneHundredBuckets = hashFunction(100, sampleOne, True)\n",
    "sampTwoHundredBuckets = hashFunction(100, sampleTwo, True)\n",
    "sampThreeHundredBuckets = hashFunction(100, sampleThree, True)\n",
    "\n",
    "print ('\\t\\t 5 Buckets \\t\\t\\t 100 Buckets')\n",
    "print ('SampleOne:\\t {0}\\t\\t {1}'.format(sampOneFiveBuckets, sampOneHundredBuckets))\n",
    "print ('SampleTwo:\\t {0}\\t\\t {1}'.format(sampTwoFiveBuckets, sampTwoHundredBuckets))\n",
    "print ('SampleThree:\\t {0}\\t {1}'.format(sampThreeFiveBuckets, sampThreeHundredBuckets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5b) Creating hashed features **\n",
    "#### Next we will use this hash function to create hashed features for our CTR datasets. First write a function that uses the hash function from Part (5a) with numBuckets = $ \\scriptsize 2^{15} \\approx 33K $ to create a `LabeledPoint` with hashed features stored as a `SparseVector`.  Then use this function to create new training, validation and test datasets with hashed features. Hint: `parsedHashPoint` is similar to `parseOHEPoint` from Part (3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (32768,[1305,2883,3807,4814,4866,4913,6952,7117,9985,10316,11512,11722,12365,13893,14735,15816,16198,17761,19274,21604,22256,22563,22785,24855,25202,25533,25721,26487,26656,27668,28211,29152,29402,29873,30039,31484,32493,32708],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    splitpoint = point.split(\",\")\n",
    "    label = splitpoint[0]\n",
    "    return LabeledPoint(label, SparseVector(numBuckets, hashFunction(numBuckets, parsePoint(point), True)))\n",
    "\n",
    "numBucketsCTR = 2 ** 15\n",
    "hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTrainData.cache()\n",
    "hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashValidationData.cache()\n",
    "hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTestData.cache()\n",
    "\n",
    "print (hashTrainData.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5c) Sparsity **\n",
    "#### Since we have 33K hashed features versus 234K OHE features, we should expect OHE features to be sparser. Verify this hypothesis by computing the average sparsity of the OHE and the hashed training datasets.\n",
    "#### Note that if you have a `SparseVector` named `sparse`, calling `len(sparse)` returns the total number of features, not the number features with entries.  `SparseVector` objects have the attributes `indices` and `values` that contain information about which features are nonzero.  Continuing with our example, these can be accessed using `sparse.indices` and `sparse.values`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OHE Sparsity: 1.6293624e-04\n",
      "Average Hash Sparsity: 1.1556060e-03\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def computeSparsity(data, d, n):\n",
    "    \"\"\"Calculates the average sparsity for the features in an RDD of LabeledPoints.\n",
    "\n",
    "    Args:\n",
    "        data (RDD of LabeledPoint): The LabeledPoints to use in the sparsity calculation.\n",
    "        d (int): The total number of features.\n",
    "        n (int): The number of observations in the RDD.\n",
    "\n",
    "    Returns:\n",
    "        float: The average of the ratio of features in a point to total features.\n",
    "    \"\"\"\n",
    "    return data.map(lambda x: len(x.features.indices)/d).sum()/n\n",
    "\n",
    "averageSparsityHash = computeSparsity(hashTrainData, numBucketsCTR, nTrain)\n",
    "averageSparsityOHE = computeSparsity(OHETrainData, numCtrOHEFeats, nTrain)\n",
    "\n",
    "print ('Average OHE Sparsity: {0:.7e}'.format(averageSparsityOHE))\n",
    "print ('Average Hash Sparsity: {0:.7e}'.format(averageSparsityHash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5d) Logistic model with hashed features **\n",
    "#### Now let's train a logistic regression model using the hashed features. Run a grid search to find suitable hyperparameters for the hashed features, evaluating via log loss on the validation data. Note: This may take a few minutes to run. Use `1` and `10` for `stepSizes` and `1e-6` and `1e-3` for `regParams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numIters = 500\n",
    "regType = 'l2'\n",
    "includeIntercept = True\n",
    "\n",
    "# Initialize variables using values from initial model training\n",
    "bestModel = None\n",
    "bestLogLoss = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstepSize = 1.0, regParam = 1e-06: logloss = 0.474\n",
      "\tstepSize = 1.0, regParam = 1e-03: logloss = 0.474\n",
      "\tstepSize = 10.0, regParam = 1e-06: logloss = 0.449\n",
      "\tstepSize = 10.0, regParam = 1e-03: logloss = 0.451\n",
      "Hashed Features Validation Logloss:\n",
      "\tBaseline = 0.530\n",
      "\tLogReg = 0.449\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "stepSizes = [1,10]\n",
    "regParams = [1e-6, 1e-3]\n",
    "for stepSize in stepSizes:\n",
    "    for regParam in regParams:\n",
    "        model = (LogisticRegressionWithSGD\n",
    "                 .train(hashTrainData, numIters, stepSize, regParam=regParam, regType=regType,\n",
    "                        intercept=includeIntercept))\n",
    "        logLossVa = evaluateResults(model, hashValidationData)\n",
    "        print ('\\tstepSize = {0:.1f}, regParam = {1:.0e}: logloss = {2:.3f}'\n",
    "               .format(stepSize, regParam, logLossVa))\n",
    "        if (logLossVa < bestLogLoss):\n",
    "            bestModel = model\n",
    "            bestLogLoss = logLossVa\n",
    "\n",
    "print ('Hashed Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossValBase, bestLogLoss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualization 3: Hyperparameter heat map**\n",
    "#### We will now perform a visualization of an extensive hyperparameter search.  Specifically, we will create a heat map where the brighter colors correspond to lower values of `logLoss`.\n",
    "#### The search was run using six step sizes and six values for regularization, which required the training of thirty-six separate models.  We have included the results below, but omitted the actual search to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Saved parameters and results.  Eliminate the time required to run 36 models\n",
    "stepSizes = [3, 6, 9, 12, 15, 18]\n",
    "regParams = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "logLoss = np.array([[ 0.45808431,  0.45808493,  0.45809113,  0.45815333,  0.45879221,  0.46556321],\n",
    "                    [ 0.45188196,  0.45188306,  0.4518941,   0.4520051,   0.45316284,  0.46396068],\n",
    "                    [ 0.44886478,  0.44886613,  0.44887974,  0.44902096,  0.4505614,   0.46371153],\n",
    "                    [ 0.44706645,  0.4470698,   0.44708102,  0.44724251,  0.44905525,  0.46366507],\n",
    "                    [ 0.44588848,  0.44589365,  0.44590568,  0.44606631,  0.44807106,  0.46365589],\n",
    "                    [ 0.44508948,  0.44509474,  0.44510274,  0.44525007,  0.44738317,  0.46365405]])\n",
    "\n",
    "numRows, numCols = len(stepSizes), len(regParams)\n",
    "logLoss = np.array(logLoss)\n",
    "logLoss.shape = (numRows, numCols)\n",
    "\n",
    "fig, ax = preparePlot(np.arange(0, numCols, 1), np.arange(0, numRows, 1), figsize=(8, 7),\n",
    "                      hideLabels=True, gridWidth=0.)\n",
    "ax.set_xticklabels(regParams), ax.set_yticklabels(stepSizes)\n",
    "ax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Step Size')\n",
    "\n",
    "colors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\n",
    "image = plt.imshow(logLoss,interpolation='nearest', aspect='auto',\n",
    "                    cmap = colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5e) Evaluate on the test set **\n",
    "#### Finally, evaluate the best model from Part (5d) on the test set.  Compare the resulting log loss with the baseline log loss on the test set, which can be computed in the same way that the validation log loss was computed in Part (4f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashed Features Test Log Loss:\n",
      "\tBaseline = 0.535\n",
      "\tLogReg = 0.455\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Log loss for the best model from (5d)\n",
    "logLossTest = evaluateResults(bestModel, hashTestData)\n",
    "\n",
    "# Log loss for the baseline model\n",
    "logLossTestBaseline = hashTestData.map(lambda x: (classOneFracTrain, x.label)).map(lambda x: computeLogLoss(x[0], x[1])).mean()\n",
    "\n",
    "print ('Hashed Features Test Log Loss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossTestBaseline, logLossTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "hw3_ctr_student",
  "notebookId": 1781086203598618
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
